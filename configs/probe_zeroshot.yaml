# probe_prompt.yaml
hydra:
  run:
    dir: outputs/hydra_logs/probes/prompt/${model.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: ??? 
  - _self_

datasets: ["city_locations", "city_locations_synthetic",
           "med_indications", "med_indications_synthetic", ...]
layers: ${model.layers}
device: null # null means use the default device (if GPU or MPS is available)
variation: "default"
output_dir: "outputs/probes/prompt/${variation}/${model.name}"

question_type: multichoice

random_seed: 42
batch_size: 12
limit_batches: -1 # number of batches to run the analysis on
enum_list: [1,2,3,4,5,6]


