{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/.local/share/virtualenvs/belief_representation-TQ_PkdhR-python/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import pickle as pkl\n",
    "import re\n",
    "from utils import DatasetGenerator\n",
    "# Parent directory\n",
    "parent_dir = str(Path().resolve().parents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drugbank to indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/.local/share/virtualenvs/belief_representation-TQ_PkdhR-python/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "pipe = pipeline(\"token-classification\", model=\"alvaroalon2/biobert_diseases_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_abbreviation(text):\n",
    "    text_clean = text.replace('.', '')\n",
    "    return text_clean.isupper() and len(text_clean) <= 5    \n",
    "\n",
    "def abbreviate(entity):\n",
    "    return ''.join([i[0] for i in entity.split()]).upper()\n",
    "\n",
    "def intersect_with_preferred_capitalization(list1, list2):\n",
    "    # Build sets of lower-cased items for each list\n",
    "    lower1 = {item.lower() for item in list1}\n",
    "    lower2 = {item.lower() for item in list2}\n",
    "    common_keys = lower1.intersection(lower2)\n",
    "\n",
    "    # Create a dictionary mapping each lowercase key to all its variations from both lists\n",
    "    mapping = {}\n",
    "    for item in list1 + list2:\n",
    "        key = item.lower()\n",
    "        if key in common_keys:\n",
    "            mapping.setdefault(key, set()).add(item)\n",
    "\n",
    "    # For each common key, choose the version that starts with an uppercase letter if available\n",
    "    result = []\n",
    "    for key, variations in mapping.items():\n",
    "        # Check if any variation is capitalized\n",
    "        preferred = next((v for v in variations if v[0].isupper()), None)\n",
    "        if preferred is None:\n",
    "            # If none are capitalized, pick an arbitrary version (sorted to be consistent)\n",
    "            preferred = sorted(variations)[0]\n",
    "        result.append(preferred)\n",
    "    return result\n",
    "\n",
    "def extract_conditions_with_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    entities = set(\n",
    "        ent.text.strip() for ent in doc.ents \n",
    "        if ent.label_ == 'DISEASE' and 2 < len(ent.text) < 50\n",
    "    )\n",
    "    return list(entities) # if remove abbreviations if entities include full names\n",
    "\n",
    "def extract_conditions_with_transformers(text):\n",
    "    res = pipe(text, aggregation_strategy=\"first\")\n",
    "    entities = set([ent['word'] for ent in res if ent['entity_group'] == 'DISEASE' and 2 < len(ent['word']) < 50])\n",
    "    return list(entities)\n",
    "\n",
    "def extract_conditions(text):\n",
    "    entities_spacy = extract_conditions_with_spacy(text)\n",
    "    entities_transformers = extract_conditions_with_transformers(text)\n",
    "    entities = intersect_with_preferred_capitalization(entities_spacy, entities_transformers)\n",
    "    abbreviations = [abbreviate(entity) for entity in entities]\n",
    "\n",
    "    output = []\n",
    "    for entity in entities:\n",
    "        if any(abbrev.upper() in entity.upper() for abbrev in abbreviations):\n",
    "            # remove abbreviations if entities include full names\n",
    "            continue\n",
    "        output.append(entity)\n",
    "\n",
    "    return list(set(entities) - set(abbreviations))\n",
    "def validate_name(text):\n",
    "    doc = nlp(text + ' ')\n",
    "    entities = set(\n",
    "        ent.text.strip() for ent in doc.ents \n",
    "        if ent.label_ == 'CHEMICAL' and 2 < len(ent.text) < 50\n",
    "    )\n",
    "    if len(entities) == 0:\n",
    "        return ''\n",
    "    return list(entities)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acute myocardial infarction', 'unstable angina', 'acute coronary syndromes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Vaginal yeast infections',\n",
       " 'fungal infection',\n",
       " 'urinary tract infection',\n",
       " 'Peritonitis',\n",
       " 'Candida infections']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text ='Lepirudin is indicated for anticoagulation in adult patients with acute coronary syndromes (ACS) such as unstable angina and acute myocardial infarction without ST elevation. In patients with ACS, lepirudin is intended for use with [aspirin].[L41539] Lepirudin is also indicated for anticoagulation in patients with heparin-induced thrombocytopenia (HIT) and associated thromboembolic disease in order to prevent further thromboembolic complications.[L41539]'\n",
    "text = text.split('.')[0]\n",
    "print(extract_conditions(text))\n",
    "text = 'Fluconazole can be administered in  the treatment of the following fungal infections[L11043]:\\r\\n\\r\\n 1) Vaginal yeast infections caused by Candida\\r\\n 2) Systemic Candida infections\\r\\n 3) Both esophageal and oropharyngeal candidiasis \\r\\n 4) Cryptococcal meningitis\\r\\n 5) UTI (urinary tract infection) by Candida\\r\\n 6) Peritonitis (inflammation of the peritoneum) caused by Candida\\r\\n\\r\\n**A note on fungal infection prophylaxis**\\r\\n\\r\\nPatients receiving bone marrow transplantation who are treated with cytotoxic chemotherapy and/or radiation therapy may be predisposed to candida infections, and may receive fluconazole as prophylactic therapy.'\n",
    "extract_conditions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "zipf_frequency('Peritonitis', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugbank = (\n",
    "    pl.read_csv(\n",
    "        f\"{parent_dir}/datasets/source/drugbank_data_with_indications.csv\",\n",
    "        columns=['Name', 'indication']\n",
    "    )\n",
    "    .drop_nulls(subset=['indication'])\n",
    "    .with_columns([\n",
    "        pl.col('indication')\n",
    "          .map_elements(lambda x: extract_conditions(x.split('.')[0]), return_dtype=pl.List(pl.String))\n",
    "          .alias('disease'),\n",
    "        pl.col('indication')\n",
    "          .map_elements(lambda x: x.split('.')[0], return_dtype=pl.String)\n",
    "          .alias('indication_simple'),\n",
    "        pl.col('Name').map_elements(lambda x: validate_name(x), return_dtype=pl.String)\n",
    "          # .str.replace(r\"\\(.*?\\)\", \"\")  \n",
    "          # .str.replace(r\"\\[.*?\\]\", \"\")  \n",
    "          # .str.split(\",\").list.get(0)  \n",
    "          .str.strip_chars()\n",
    "          .alias('chemical')\n",
    "        # pl.col\n",
    "    ])\n",
    "    .filter(pl.col('chemical').str.len_chars() > 0)\n",
    "    # Properly clean each disease name within the list\n",
    "    .with_columns(\n",
    "        pl.col('disease').map_elements(\n",
    "            lambda disease_list: sorted({\n",
    "                re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", d)\n",
    "                  .split(\",\")[0]\n",
    "                  .strip(\"#+ \")\n",
    "                  .replace('-', ' ')\n",
    "                  .strip()\n",
    "                for d in disease_list\n",
    "            }),\n",
    "            return_dtype=pl.List(pl.String)\n",
    "        ).alias('disease_clean')\n",
    "    )\n",
    "    .filter(pl.col('disease_clean').list.len() > 0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugbank.write_json(f\"{parent_dir}/datasets/source/drugbank_data_with_indications_clean.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugdict = dict(\n",
    "    drugbank.select(['Name', 'disease_clean']).iter_rows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugDisease(DatasetGenerator):\n",
    "    '''\n",
    "    Class to handle the dataset from DrugBank\n",
    "    '''\n",
    "    def apply_template(self, drug: str, condition: str, negated: bool=False):\n",
    "        if negated:\n",
    "            return f\"{drug} is not indicated for the treatment of {condition}.\"\n",
    "        else:\n",
    "            return f\"{drug} is indicated for the treatment of {condition}.\"\n",
    "        \n",
    "        \n",
    "\n",
    "    def lookup_incorrect(self, key) -> str:\n",
    "        '''\n",
    "        Return False condition for a given drug\n",
    "        '''\n",
    "        correct = self.source[key]\n",
    "        choice = random.choice(list(set(self.values) - set(correct)))\n",
    "        if choice.lower() in [c.lower() for c in correct]:\n",
    "            return self.lookup_incorrect(key)\n",
    "        elif abbreviate(choice) in [abbreviate(c) for c in correct] or abbreviate(choice) in [c for c in correct]:\n",
    "            return self.lookup_incorrect(key)\n",
    "        elif any(word in c.lower().split() for word in choice.lower().split() for c in correct):\n",
    "            return self.lookup_incorrect(key)\n",
    "        return choice\n",
    "    \n",
    "db = DrugDisease(drugdict, category='indications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blood loss',\n",
       " ['acute coronary syndromes',\n",
       "  'acute myocardial infarction',\n",
       "  'unstable angina'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.lookup_incorrect('Lepirudin'), db.source['Lepirudin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db.generate_full_dataset()\n",
    "data.write_json(f\"{parent_dir}/datasets/source/drug_disease.json\")\n",
    "subsample = db.generate_subsample(n = 5000, seed=42).with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample.write_csv(f\"{parent_dir}/datasets/drug_disease_subsample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_frequencies(word):\n",
    "    freq  = zipf_frequency(word, 'en', minimum=0.0, wordlist='best')\n",
    "    if freq == 0: \n",
    "        random.seed(word)\n",
    "        if random.random() < 0.1: # keep a small amount of words with 0 frequency\n",
    "            freq = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>correct</th><th>negation</th><th>len</th></tr><tr><td>bool</td><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>false</td><td>false</td><td>1419</td></tr><tr><td>true</td><td>false</td><td>1522</td></tr><tr><td>true</td><td>true</td><td>1439</td></tr><tr><td>false</td><td>true</td><td>1523</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌─────────┬──────────┬──────┐\n",
       "│ correct ┆ negation ┆ len  │\n",
       "│ ---     ┆ ---      ┆ ---  │\n",
       "│ bool    ┆ bool     ┆ u32  │\n",
       "╞═════════╪══════════╪══════╡\n",
       "│ false   ┆ false    ┆ 1419 │\n",
       "│ true    ┆ false    ┆ 1522 │\n",
       "│ true    ┆ true     ┆ 1439 │\n",
       "│ false   ┆ true     ┆ 1523 │\n",
       "└─────────┴──────────┴──────┘"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample = db.generate_full_dataset().with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample = subsample.with_columns(\n",
    "    pl.col('object_1').map_elements(lambda x: get_rand_frequencies(x.lower()), return_dtype=float).alias('freq_1'),\n",
    "    pl.col('object_2').map_elements(lambda x: get_rand_frequencies(x.lower()), return_dtype=float).alias('freq_2'),\n",
    ").filter((pl.col('freq_1') > 0) & (pl.col('freq_2') > 0))\n",
    "subsample.write_csv(f\"{parent_dir}/datasets/drug_disease_full.csv\")\n",
    "subsample.group_by(['correct', 'negation']).len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Statements\n",
    "### Generator for the Drugs and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from namemaker import NameSet\n",
    "import namemaker\n",
    "\n",
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "random.seed(seed)\n",
    "namemaker_rng = namemaker.get_rng()\n",
    "namemaker_rng.seed(seed)\n",
    "\n",
    "drug_NS = NameSet(names = drugdict.keys())\n",
    "drugs_fake = [drug_NS.make_name(add_to_history=False) for _ in range(500)]\n",
    "drugs_fake = list(set(drugs_fake))\n",
    "# Validate\n",
    "drugs_validated = []\n",
    "for item in drugs_fake:\n",
    "    if validate_name(item) != '':\n",
    "        pass\n",
    "    else:\n",
    "        drugs_validated.append(item)\n",
    "with open(f\"{parent_dir}/datasets/source/IDK_drugs_v2.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, drugs_validated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "random.seed(seed)\n",
    "namemaker_rng = namemaker.get_rng()\n",
    "namemaker_rng.seed(seed)\n",
    "condition_NS = NameSet(names = db.values)\n",
    "conditions_fake = [condition_NS.make_name(add_to_history=False) for _ in range(200)]\n",
    "conditions_validated = []\n",
    "for item in conditions_fake:\n",
    "    if any([item.lower() in c.lower() for c in db.values]):\n",
    "        pass\n",
    "    else:\n",
    "        conditions_validated.append(item)\n",
    "with open(f\"{parent_dir}/datasets/source/IDK_diseases_v2.txt\", 'w') as f:\n",
    "        f.write(\"\\n\".join(map(str, conditions_validated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Unverifiable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "IDK_drugs = pd.read_csv(f\"{parent_dir}/datasets/source/IDK_drugs_checked_v2.csv\")\n",
    "IDK_drugs = IDK_drugs[IDK_drugs['Keep'] == 1]\n",
    "IDK_drugs = IDK_drugs['Name'].tolist()\n",
    "\n",
    "IDK_conditions = pd.read_csv(f\"{parent_dir}/datasets/source/IDK_diseases_checked_v2.csv\")\n",
    "IDK_conditions = IDK_conditions[IDK_conditions['Keep'] == 1]\n",
    "IDK_conditions = IDK_conditions['Name'].tolist()\n",
    "random.seed(seed)\n",
    "fake_indications = {}\n",
    "for drug in IDK_drugs:\n",
    "    fake_indications[drug] = random.sample(IDK_conditions, 2)\n",
    "#fake_indications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statement</th><th>object_1</th><th>object_2</th><th>correct_object_2</th><th>correct</th><th>negation</th><th>real_object</th><th>fake_object</th><th>fictional_object</th><th>category</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;Alumil is indicated for the tr…</td><td>&quot;Alumil&quot;</td><td>&quot;reticers&quot;</td><td>&quot;candigemia, reticers&quot;</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Cysternime is not indicated fo…</td><td>&quot;Cysternime&quot;</td><td>&quot;perebrilepsies&quot;</td><td>&quot;perebrilepsies, nonvalvulgaris&quot;</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Neostonicone is not indicated …</td><td>&quot;Neostonicone&quot;</td><td>&quot;delial brease&quot;</td><td>&quot;delial brease, breatory disord…</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Buspium is indicated for the t…</td><td>&quot;Buspium&quot;</td><td>&quot;perlipidematory loss&quot;</td><td>&quot;perlipidematory loss, uronchos…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Azelanzamide is indicated for …</td><td>&quot;Azelanzamide&quot;</td><td>&quot;hepathe overampsis&quot;</td><td>&quot;hepathe overampsis, acular aci…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Deutetractone is indicated for…</td><td>&quot;Deutetractone&quot;</td><td>&quot;atori infective Disease&quot;</td><td>&quot;atori infective Disease, intri…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Tramaltolamide is indicated fo…</td><td>&quot;Tramaltolamide&quot;</td><td>&quot;akine disorders&quot;</td><td>&quot;hyperampsies, anal bleepischem…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Glutalacine is indicated for t…</td><td>&quot;Glutalacine&quot;</td><td>&quot;sorder cand vomiasis&quot;</td><td>&quot;asperpetiformis, sorder cand v…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Fenose is not indicated for th…</td><td>&quot;Fenose&quot;</td><td>&quot;dyslipolyneury&quot;</td><td>&quot;Onychoticus, dyslipolyneury&quot;</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Propa is not indicated for the…</td><td>&quot;Propa&quot;</td><td>&quot;breatory disorders&quot;</td><td>&quot;ovasospasmosis, astroid cancer&quot;</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statement ┆ object_1  ┆ object_2  ┆ correct_o ┆ … ┆ real_obje ┆ fake_obje ┆ fictional ┆ category │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ bject_2   ┆   ┆ ct        ┆ ct        ┆ _object   ┆ ---      │\n",
       "│ str       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ str      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ bool      ┆ bool      ┆ bool      ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Alumil is ┆ Alumil    ┆ reticers  ┆ candigemi ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ indicated ┆           ┆           ┆ a,        ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ for the   ┆           ┆           ┆ reticers  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ tr…       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Cysternim ┆ Cysternim ┆ perebrile ┆ perebrile ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ e is not  ┆ e         ┆ psies     ┆ psies,    ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ nonvalvul ┆   ┆           ┆           ┆           ┆          │\n",
       "│ fo…       ┆           ┆           ┆ garis     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Neostonic ┆ Neostonic ┆ delial    ┆ delial    ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ one is    ┆ one       ┆ brease    ┆ brease,   ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ not       ┆           ┆           ┆ breatory  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ indicated ┆           ┆           ┆ disord…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Buspium   ┆ Buspium   ┆ perlipide ┆ perlipide ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ is        ┆           ┆ matory    ┆ matory    ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ loss      ┆ loss,     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for the   ┆           ┆           ┆ uronchos… ┆   ┆           ┆           ┆           ┆          │\n",
       "│ t…        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Azelanzam ┆ Azelanzam ┆ hepathe   ┆ hepathe   ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ ide is    ┆ ide       ┆ overampsi ┆ overampsi ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ s         ┆ s, acular ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for …     ┆           ┆           ┆ aci…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Deutetrac ┆ Deutetrac ┆ atori     ┆ atori     ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ tone is   ┆ tone      ┆ infective ┆ infective ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ Disease   ┆ Disease,  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for…      ┆           ┆           ┆ intri…    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Tramaltol ┆ Tramaltol ┆ akine     ┆ hyperamps ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ amide is  ┆ amide     ┆ disorders ┆ ies, anal ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ bleepisch ┆   ┆           ┆           ┆           ┆          │\n",
       "│ fo…       ┆           ┆           ┆ em…       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Glutalaci ┆ Glutalaci ┆ sorder    ┆ asperpeti ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ ne is     ┆ ne        ┆ cand      ┆ formis,   ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ vomiasis  ┆ sorder    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for t…    ┆           ┆           ┆ cand v…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Fenose is ┆ Fenose    ┆ dyslipoly ┆ Onychotic ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ not       ┆           ┆ neury     ┆ us, dysli ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ polyneury ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for th…   ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Propa is  ┆ Propa     ┆ breatory  ┆ ovasospas ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ not       ┆           ┆ disorders ┆ mosis,    ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ astroid   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for the…  ┆           ┆           ┆ cancer    ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_fake = DrugDisease(fake_indications, is_fake=True, \n",
    "                      category='indications')\n",
    "data_fake = db_fake.generate_full_dataset()\n",
    "data_fake.write_json(f\"{parent_dir}/datasets/source/drug_disease_fake.json\")\n",
    "subsample_fake = db_fake.generate_subsample(n = 1000, seed=42).with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample_fake.write_csv(f\"{parent_dir}/datasets/drug_disease_synth_subsample.csv\")\n",
    "subsample_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_43742/1563926242.py:1: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  subsample_fake.filter(pl.col('real_object')==False).group_by(['negation']).count()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>negation</th><th>count</th></tr><tr><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>true</td><td>522</td></tr><tr><td>false</td><td>478</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌──────────┬───────┐\n",
       "│ negation ┆ count │\n",
       "│ ---      ┆ ---   │\n",
       "│ bool     ┆ u32   │\n",
       "╞══════════╪═══════╡\n",
       "│ true     ┆ 522   │\n",
       "│ false    ┆ 478   │\n",
       "└──────────┴───────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample_fake.filter(pl.col('real_object')==False).group_by(['negation']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belief_representation-TQ_PkdhR-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
