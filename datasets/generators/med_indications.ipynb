{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Indications (Dataset)\n",
    "Here, we provide a code to collect and process the dataset of *Drugs/Chemicals* and corresponding *Indications/Diseases*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "from utils import DrugDisease, abbreviate\n",
    "from wordfreq import zipf_frequency\n",
    "# Parent directory\n",
    "parent_dir = str(Path().resolve().parents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract data from the `DrugBank` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/.local/share/virtualenvs/belief_representation-TQ_PkdhR-python/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from transformers import pipeline\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "pipe = pipeline(\"token-classification\", model=\"alvaroalon2/biobert_diseases_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def is_abbreviation(text: str) -> bool:\n",
    "    ''' \n",
    "        Check if the text is an abbreviation.\n",
    "    '''\n",
    "    text_clean = text.replace('.', '')\n",
    "    return text_clean.isupper() and len(text_clean) <= 5    \n",
    "\n",
    "def intersect_with_preferred_capitalization(list1, list2):\n",
    "    ''' \n",
    "        Find common items in two lists, preferring capitalized versions.\n",
    "    '''\n",
    "    # Build sets of lower-cased items for each list\n",
    "    lower1 = {item.lower() for item in list1}\n",
    "    lower2 = {item.lower() for item in list2}\n",
    "    common_keys = lower1.intersection(lower2)\n",
    "\n",
    "    # Create a dictionary mapping each lowercase key to all its variations from both lists\n",
    "    mapping = {}\n",
    "    for item in list1 + list2:\n",
    "        key = item.lower()\n",
    "        if key in common_keys:\n",
    "            mapping.setdefault(key, set()).add(item)\n",
    "\n",
    "    # For each common key, choose the version that starts with an uppercase letter if available\n",
    "    result = []\n",
    "    for key, variations in mapping.items():\n",
    "        # Check if any variation is capitalized\n",
    "        preferred = next((v for v in variations if v[0].isupper()), None)\n",
    "        if preferred is None:\n",
    "            # If none are capitalized, pick an arbitrary version (sorted to be consistent)\n",
    "            preferred = sorted(variations)[0]\n",
    "        result.append(preferred)\n",
    "    return result\n",
    "\n",
    "def extract_conditions_with_spacy(text):\n",
    "    '''\n",
    "        Extract disease entities from text using spaCy.\n",
    "        Returns a list of unique disease names.\n",
    "    '''\n",
    "    doc = nlp(text)\n",
    "    entities = set(\n",
    "        ent.text.strip() for ent in doc.ents \n",
    "        if ent.label_ == 'DISEASE' and 2 < len(ent.text) < 50\n",
    "    )\n",
    "    return list(entities) # if remove abbreviations if entities include full names\n",
    "\n",
    "def extract_conditions_with_transformers(text):\n",
    "    '''\n",
    "        Extract disease entities from text using transformers.\n",
    "        Returns a list of unique disease names.\n",
    "    '''\n",
    "    res = pipe(text, aggregation_strategy=\"first\")\n",
    "    entities = set([ent['word'] for ent in res if ent['entity_group'] == 'DISEASE' and 2 < len(ent['word']) < 50])\n",
    "    return list(entities)\n",
    "\n",
    "def extract_conditions(text):\n",
    "    '''\n",
    "        Extract disease entities from text using both spaCy and transformers.\n",
    "        Returns a list of unique disease names, preferring capitalized versions.\n",
    "    '''\n",
    "    entities_spacy = extract_conditions_with_spacy(text)\n",
    "    entities_transformers = extract_conditions_with_transformers(text)\n",
    "    entities = intersect_with_preferred_capitalization(entities_spacy, entities_transformers)\n",
    "    abbreviations = [abbreviate(entity) for entity in entities]\n",
    "\n",
    "    output = []\n",
    "    for entity in entities:\n",
    "        if any(abbrev.upper() in entity.upper() for abbrev in abbreviations):\n",
    "            # remove abbreviations if entities include full names\n",
    "            continue\n",
    "        output.append(entity)\n",
    "\n",
    "    return list(set(entities) - set(abbreviations))\n",
    "def validate_name(text):\n",
    "    '''\n",
    "        Validate if the text is a valid name for a disease or chemical.\n",
    "        Returns the name if valid, otherwise returns an empty string.\n",
    "    '''\n",
    "    doc = nlp(text + ' ')\n",
    "    entities = set(\n",
    "        ent.text.strip() for ent in doc.ents \n",
    "        if ent.label_ == 'CHEMICAL' and 2 < len(ent.text) < 50\n",
    "    )\n",
    "    if len(entities) == 0:\n",
    "        return ''\n",
    "    return list(entities)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the validation function\n",
    "text ='Lepirudin is indicated for anticoagulation in adult patients with acute coronary syndromes (ACS) such as unstable angina and acute myocardial infarction without ST elevation. In patients with ACS, lepirudin is intended for use with [aspirin].[L41539] Lepirudin is also indicated for anticoagulation in patients with heparin-induced thrombocytopenia (HIT) and associated thromboembolic disease in order to prevent further thromboembolic complications.[L41539]'\n",
    "text = text.split('.')[0]\n",
    "print(extract_conditions(text))\n",
    "text = 'Fluconazole can be administered in  the treatment of the following fungal infections[L11043]:\\r\\n\\r\\n 1) Vaginal yeast infections caused by Candida\\r\\n 2) Systemic Candida infections\\r\\n 3) Both esophageal and oropharyngeal candidiasis \\r\\n 4) Cryptococcal meningitis\\r\\n 5) UTI (urinary tract infection) by Candida\\r\\n 6) Peritonitis (inflammation of the peritoneum) caused by Candida\\r\\n\\r\\n**A note on fungal infection prophylaxis**\\r\\n\\r\\nPatients receiving bone marrow transplantation who are treated with cytotoxic chemotherapy and/or radiation therapy may be predisposed to candida infections, and may receive fluconazole as prophylactic therapy.'\n",
    "extract_conditions(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drugbank_data_with_indications.csv` should be requested from the `DrugBank` (we do not provide it in this repository)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugbank = (\n",
    "    pl.read_csv(\n",
    "        f\"{parent_dir}/datasets/generators/drugbank_data_with_indications.csv\",\n",
    "        columns=['Name', 'indication']\n",
    "    )\n",
    "    .drop_nulls(subset=['indication'])\n",
    "    .with_columns([\n",
    "        pl.col('indication')\n",
    "          .map_elements(lambda x: extract_conditions(x.split('.')[0]), return_dtype=pl.List(pl.String))\n",
    "          .alias('disease'),\n",
    "        pl.col('indication')\n",
    "          .map_elements(lambda x: x.split('.')[0], return_dtype=pl.String)\n",
    "          .alias('indication_simple'),\n",
    "        pl.col('Name').map_elements(lambda x: validate_name(x), return_dtype=pl.String)\n",
    "          .str.strip_chars()\n",
    "          .alias('chemical')\n",
    "    ])\n",
    "    .filter(pl.col('chemical').str.len_chars() > 0)\n",
    "    # Properly clean each disease name within the list\n",
    "    .with_columns(\n",
    "        pl.col('disease').map_elements(\n",
    "            lambda disease_list: sorted({\n",
    "                re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", d)\n",
    "                  .split(\",\")[0]\n",
    "                  .strip(\"#+ \")\n",
    "                  .replace('-', ' ')\n",
    "                  .strip()\n",
    "                for d in disease_list\n",
    "            }),\n",
    "            return_dtype=pl.List(pl.String)\n",
    "        ).alias('disease_clean')\n",
    "    )\n",
    "    .filter(pl.col('disease_clean').list.len() > 0)\n",
    ")\n",
    "drugbank.write_json(f\"{parent_dir}/datasets/source/drugbank_data_with_indications_clean.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate `true` and `false` statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugdict = dict(\n",
    "    drugbank.select(['Name', 'disease_clean']).iter_rows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DrugDisease(drugdict, category='indications')\n",
    "##  check if the drugbank data is loaded correctly\n",
    "db.lookup_incorrect('Lepirudin'), db.source['Lepirudin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not provide the `med_indications.json` (since it includes a large portion of the `DrugBank` data, you can request the `DrugBank` data via the academic license)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db.generate_full_dataset()\n",
    "data.write_json(f\"{parent_dir}/datasets/generators/med_indications.json\")\n",
    "subsample = db.generate_subsample(n = 5000, seed=42).with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample.write_csv(f\"{parent_dir}/datasets/med_indications.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_frequencies(word):\n",
    "    freq  = zipf_frequency(word, 'en', minimum=0.0, wordlist='best')\n",
    "    if freq == 0: \n",
    "        random.seed(word)\n",
    "        if random.random() < 0.1: # keep a small amount of words with 0 frequency\n",
    "            freq = 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>correct</th><th>negation</th><th>len</th></tr><tr><td>bool</td><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>false</td><td>false</td><td>1419</td></tr><tr><td>true</td><td>false</td><td>1522</td></tr><tr><td>true</td><td>true</td><td>1439</td></tr><tr><td>false</td><td>true</td><td>1523</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌─────────┬──────────┬──────┐\n",
       "│ correct ┆ negation ┆ len  │\n",
       "│ ---     ┆ ---      ┆ ---  │\n",
       "│ bool    ┆ bool     ┆ u32  │\n",
       "╞═════════╪══════════╪══════╡\n",
       "│ false   ┆ false    ┆ 1419 │\n",
       "│ true    ┆ false    ┆ 1522 │\n",
       "│ true    ┆ true     ┆ 1439 │\n",
       "│ false   ┆ true     ┆ 1523 │\n",
       "└─────────┴──────────┴──────┘"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample = db.generate_full_dataset().with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample = subsample.with_columns(\n",
    "    pl.col('object_1').map_elements(lambda x: get_rand_frequencies(x.lower()), return_dtype=float).alias('freq_1'),\n",
    "    pl.col('object_2').map_elements(lambda x: get_rand_frequencies(x.lower()), return_dtype=float).alias('freq_2'),\n",
    ").filter((pl.col('freq_1') > 0) & (pl.col('freq_2') > 0))\n",
    "subsample.write_csv(f\"{parent_dir}/datasets/drug_disease_full.csv\")\n",
    "subsample.group_by(['correct', 'negation']).len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Syntetic Entities\n",
    "Here, we generate synthetic names for countries and cities. \n",
    "Generated names are stored in `datasets/generators/synthetic/*_raw.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from namemaker import NameSet\n",
    "import namemaker\n",
    "\n",
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "random.seed(seed)\n",
    "namemaker_rng = namemaker.get_rng()\n",
    "namemaker_rng.seed(seed)\n",
    "\n",
    "drug_NS = NameSet(names = drugdict.keys())\n",
    "drugs_fake = [drug_NS.make_name(add_to_history=False) for _ in range(500)]\n",
    "drugs_fake = list(set(drugs_fake))\n",
    "# Validate\n",
    "drugs_validated = []\n",
    "for item in drugs_fake:\n",
    "    if validate_name(item) != '':\n",
    "        pass\n",
    "    else:\n",
    "        drugs_validated.append(item)\n",
    "with open(f\"{parent_dir}/datasets/generators/synthetic/drugnames_raw.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, drugs_validated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "random.seed(seed)\n",
    "namemaker_rng = namemaker.get_rng()\n",
    "namemaker_rng.seed(seed)\n",
    "condition_NS = NameSet(names = db.values)\n",
    "conditions_fake = [condition_NS.make_name(add_to_history=False) for _ in range(200)]\n",
    "conditions_validated = []\n",
    "for item in conditions_fake:\n",
    "    if any([item.lower() in c.lower() for c in db.values]):\n",
    "        pass\n",
    "    else:\n",
    "        conditions_validated.append(item)\n",
    "with open(f\"{parent_dir}/datasets/generators/synthetic/indications_raw.txt\", 'w') as f:\n",
    "        f.write(\"\\n\".join(map(str, conditions_validated)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create `neither` statements\n",
    "Here, we load the list of names that we manually checked (i.e., filtered raw files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "IDK_drugs = pd.read_csv(f\"{parent_dir}/datasets/generators/synthetic/drugnames_checked.csv\")\n",
    "IDK_drugs = IDK_drugs[IDK_drugs['Keep'] == 1]\n",
    "IDK_drugs = IDK_drugs['Name'].tolist()\n",
    "\n",
    "IDK_conditions = pd.read_csv(f\"{parent_dir}/datasets/generators/synthetic/indications_checked.csv\")\n",
    "IDK_conditions = IDK_conditions[IDK_conditions['Keep'] == 1]\n",
    "IDK_conditions = IDK_conditions['Name'].tolist()\n",
    "random.seed(seed)\n",
    "fake_indications = {}\n",
    "for drug in IDK_drugs:\n",
    "    fake_indications[drug] = random.sample(IDK_conditions, 2)\n",
    "#fake_indications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statement</th><th>object_1</th><th>object_2</th><th>correct_object_2</th><th>correct</th><th>negation</th><th>real_object</th><th>fake_object</th><th>fictional_object</th><th>category</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;Alumil is indicated for the tr…</td><td>&quot;Alumil&quot;</td><td>&quot;reticers&quot;</td><td>&quot;candigemia, reticers&quot;</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Cysternime is not indicated fo…</td><td>&quot;Cysternime&quot;</td><td>&quot;perebrilepsies&quot;</td><td>&quot;perebrilepsies, nonvalvulgaris&quot;</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Neostonicone is not indicated …</td><td>&quot;Neostonicone&quot;</td><td>&quot;delial brease&quot;</td><td>&quot;delial brease, breatory disord…</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Buspium is indicated for the t…</td><td>&quot;Buspium&quot;</td><td>&quot;perlipidematory loss&quot;</td><td>&quot;perlipidematory loss, uronchos…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Azelanzamide is indicated for …</td><td>&quot;Azelanzamide&quot;</td><td>&quot;hepathe overampsis&quot;</td><td>&quot;hepathe overampsis, acular aci…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Deutetractone is indicated for…</td><td>&quot;Deutetractone&quot;</td><td>&quot;atori infective Disease&quot;</td><td>&quot;atori infective Disease, intri…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Tramaltolamide is indicated fo…</td><td>&quot;Tramaltolamide&quot;</td><td>&quot;akine disorders&quot;</td><td>&quot;hyperampsies, anal bleepischem…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Glutalacine is indicated for t…</td><td>&quot;Glutalacine&quot;</td><td>&quot;sorder cand vomiasis&quot;</td><td>&quot;asperpetiformis, sorder cand v…</td><td>false</td><td>false</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Fenose is not indicated for th…</td><td>&quot;Fenose&quot;</td><td>&quot;dyslipolyneury&quot;</td><td>&quot;Onychoticus, dyslipolyneury&quot;</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr><tr><td>&quot;Propa is not indicated for the…</td><td>&quot;Propa&quot;</td><td>&quot;breatory disorders&quot;</td><td>&quot;ovasospasmosis, astroid cancer&quot;</td><td>false</td><td>true</td><td>false</td><td>true</td><td>false</td><td>&quot;indications&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statement ┆ object_1  ┆ object_2  ┆ correct_o ┆ … ┆ real_obje ┆ fake_obje ┆ fictional ┆ category │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ bject_2   ┆   ┆ ct        ┆ ct        ┆ _object   ┆ ---      │\n",
       "│ str       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ str      │\n",
       "│           ┆           ┆           ┆ str       ┆   ┆ bool      ┆ bool      ┆ bool      ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Alumil is ┆ Alumil    ┆ reticers  ┆ candigemi ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ indicated ┆           ┆           ┆ a,        ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ for the   ┆           ┆           ┆ reticers  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ tr…       ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Cysternim ┆ Cysternim ┆ perebrile ┆ perebrile ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ e is not  ┆ e         ┆ psies     ┆ psies,    ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ nonvalvul ┆   ┆           ┆           ┆           ┆          │\n",
       "│ fo…       ┆           ┆           ┆ garis     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Neostonic ┆ Neostonic ┆ delial    ┆ delial    ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ one is    ┆ one       ┆ brease    ┆ brease,   ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ not       ┆           ┆           ┆ breatory  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ indicated ┆           ┆           ┆ disord…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Buspium   ┆ Buspium   ┆ perlipide ┆ perlipide ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ is        ┆           ┆ matory    ┆ matory    ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ loss      ┆ loss,     ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for the   ┆           ┆           ┆ uronchos… ┆   ┆           ┆           ┆           ┆          │\n",
       "│ t…        ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Azelanzam ┆ Azelanzam ┆ hepathe   ┆ hepathe   ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ ide is    ┆ ide       ┆ overampsi ┆ overampsi ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ s         ┆ s, acular ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for …     ┆           ┆           ┆ aci…      ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Deutetrac ┆ Deutetrac ┆ atori     ┆ atori     ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ tone is   ┆ tone      ┆ infective ┆ infective ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ Disease   ┆ Disease,  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for…      ┆           ┆           ┆ intri…    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Tramaltol ┆ Tramaltol ┆ akine     ┆ hyperamps ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ amide is  ┆ amide     ┆ disorders ┆ ies, anal ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ bleepisch ┆   ┆           ┆           ┆           ┆          │\n",
       "│ fo…       ┆           ┆           ┆ em…       ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Glutalaci ┆ Glutalaci ┆ sorder    ┆ asperpeti ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ ne is     ┆ ne        ┆ cand      ┆ formis,   ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆ vomiasis  ┆ sorder    ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for t…    ┆           ┆           ┆ cand v…   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Fenose is ┆ Fenose    ┆ dyslipoly ┆ Onychotic ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ not       ┆           ┆ neury     ┆ us, dysli ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ polyneury ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for th…   ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Propa is  ┆ Propa     ┆ breatory  ┆ ovasospas ┆ … ┆ false     ┆ true      ┆ false     ┆ indicati │\n",
       "│ not       ┆           ┆ disorders ┆ mosis,    ┆   ┆           ┆           ┆           ┆ ons      │\n",
       "│ indicated ┆           ┆           ┆ astroid   ┆   ┆           ┆           ┆           ┆          │\n",
       "│ for the…  ┆           ┆           ┆ cancer    ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_fake = DrugDisease(fake_indications, is_fake=True, \n",
    "                      category='indications')\n",
    "data_fake = db_fake.generate_full_dataset()\n",
    "data_fake.write_json(f\"{parent_dir}/datasets/generators/med_indications_synthetic.json\")\n",
    "subsample_fake = db_fake.generate_subsample(n = 1000, seed=42).with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample_fake.write_csv(f\"{parent_dir}/datasets/med_indications_synthetic.csv\")\n",
    "subsample_fake"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belief-representation-dS6b1P8F-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
