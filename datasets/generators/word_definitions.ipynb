{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import inflect\n",
    "import spacy\n",
    "import numpy as np\n",
    "from utils import DatasetGenerator\n",
    "# imports\n",
    "from pathlib import Path\n",
    "# Parent directory\n",
    "parent_dir = str(Path().resolve().parents[0])\n",
    "import polars as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "def check_if_pnoun(term, definition):\n",
    "    \"\"\"\n",
    "    Check if the term is a proper noun\n",
    "    \"\"\"\n",
    "    term_len = len(term)\n",
    "    doc = nlp(f\"{term} is {definition}\")\n",
    "    for token in doc[:term_len]:\n",
    "        if token.pos_ == \"PROPN\":\n",
    "            ent_type = token.ent_type_\n",
    "            if ent_type == \"\":\n",
    "                return \"PROPN\"\n",
    "            else:\n",
    "                return ent_type\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSON'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "doc = nlp(\"Harrison is defined as a 9th president of the united states\")\n",
    "check_if_pnoun(\"madam\", \"a 9th president of the united states.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"hasTypes\", \"typeOf\",\n",
    "                \"partOf\", \"hasParts\",\n",
    "                \"instanceOf\", \"hasInstances\",\n",
    "                \"memberOf\", \"hasMembers\",\n",
    "                \"substanceOf\", \"hasSubstances\",\n",
    "                \"inCategory\", \"hasCategories\",\n",
    "                \"regionOf\", \"inRegion\"]\n",
    "def check_attributes(word: dict):\n",
    "    keys = list(word.keys())\n",
    "    if \"definitions\" in keys:\n",
    "        if type(word[\"definitions\"]) == list:\n",
    "            for w in word[\"definitions\"]:\n",
    "                sub_keys = w.keys()\n",
    "                if \"synonyms\" in sub_keys and \"definition\" in sub_keys and \"partOfSpeech\" in sub_keys and any(keyword in sub_keys for keyword in keywords):\n",
    "                    pass\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            sub_keys = word[\"definitions\"].keys()\n",
    "            if \"synonyms\" in sub_keys and \"definition\" in sub_keys and \"partOfSpeech\" in sub_keys and any(keyword in sub_keys for keyword in keywords):\n",
    "                pass\n",
    "            else:\n",
    "                return False\n",
    "    else:\n",
    "        return False\n",
    "    if \"frequency\" not in keys:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Initialize the inflect engine\n",
    "p = inflect.engine()\n",
    "exceptions = (\"any\", \"one\", \"once\", 'something', 'someone', 'somebody', 'anything', 'anyone', 'anybody')\n",
    "def format_definitions(definition, part_of_speech):\n",
    "    # Remove text within brackets\n",
    "    definition = re.sub(r'\\s*\\(.*?\\)\\s*', ' ', definition).strip()\n",
    "    \n",
    "    # Check the first character of the definition to decide on the article\n",
    "    definition = definition.strip()\n",
    "    # Use the first part of the definition\\\n",
    "    definition = definition.split(';')[0]\n",
    "\n",
    "    if part_of_speech == \"noun\":\n",
    "        lower_definition = definition.lower()\n",
    "        \n",
    "        # Check specific cases where no article should be used\n",
    "        if lower_definition.startswith(exceptions):\n",
    "            article = ''\n",
    "        else:\n",
    "            # Use inflect to determine the correct article\n",
    "            article = p.a(definition).split()[0]\n",
    "        \n",
    "        # Check if the definition already starts with an article or 'the'\n",
    "        if not lower_definition.startswith(('a ', 'an ', 'the ')) and article:\n",
    "            definition = f\"{article} {definition}\"\n",
    "    elif part_of_speech == \"verb\":\n",
    "        if not definition.startswith(\"to \"):\n",
    "            definition = f\"to {definition}\"\n",
    "\n",
    "    if definition.endswith('.'):\n",
    "        definition = definition[:-1]\n",
    "    \n",
    "    return definition.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 1641\n"
     ]
    }
   ],
   "source": [
    "with open(parent_dir + '/source/wordsapi_sample.json') as f:\n",
    "    data = json.load(f)\n",
    "keys = data.keys()\n",
    "valid_keys = [key for key in keys if check_attributes(data[key])]\n",
    "print(\"Number of words:\", len(valid_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "extended_keywords = keywords + [\"definition\", \"synonyms\", \"partOfSpeech\"]\n",
    "for key in valid_keys:\n",
    "    word = data[key]\n",
    "    freq = word[\"frequency\"]\n",
    "    if type(freq) == dict:\n",
    "        zipf = freq[\"zipf\"]\n",
    "        perMillion = freq[\"perMillion\"]\n",
    "        diversity = freq[\"diversity\"]\n",
    "    else:\n",
    "        zipf = freq\n",
    "        perMillion = None\n",
    "        diversity = None\n",
    "\n",
    "    if \"letters\" in word.keys():\n",
    "        letters = word[\"letters\"]\n",
    "    else:\n",
    "        letters = None\n",
    "    if \"sounds\" in word.keys():\n",
    "        sounds = word[\"sounds\"]\n",
    "    else:\n",
    "        sounds = None\n",
    "    if type(word[\"definitions\"]) == list:\n",
    "        for w in word[\"definitions\"]:\n",
    "            _word = {k:v for k,v in w.items() if k in extended_keywords}\n",
    "            _word[\"word\"] = key\n",
    "            _word[\"zipf\"] = zipf\n",
    "            _word[\"perMillion\"] = perMillion\n",
    "            _word[\"diversity\"] = diversity\n",
    "            _word[\"letters\"] = letters\n",
    "            _word[\"sounds\"] = sounds\n",
    "            _word[\"definition\"] = format_definitions(_word[\"definition\"], _word[\"partOfSpeech\"])\n",
    "            _word[\"num_definitions\"] = len(word[\"definitions\"])\n",
    "            word_list.append(_word)\n",
    "    else:\n",
    "        _word = {k:v for k,v in word[\"definitions\"].items() if k in extended_keywords}\n",
    "        _word[\"word\"] = key\n",
    "        _word[\"zipf\"] = zipf\n",
    "        _word[\"perMillion\"] = perMillion\n",
    "        _word[\"diversity\"] = diversity\n",
    "        _word[\"letters\"] = letters\n",
    "        _word[\"sounds\"] = sounds\n",
    "        _word[\"definition\"] = format_definitions(_word[\"definition\"], _word[\"partOfSpeech\"])\n",
    "        _word[\"num_definitions\"] = 1\n",
    "\n",
    "        word_list.append(_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlomarx/.local/share/virtualenvs/belief_representation-TQ_PkdhR-python/lib/python3.11/site-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (628, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>word</th><th>definition</th><th>partOfSpeech</th><th>pnoun</th><th>synonyms</th><th>hasTypes</th><th>typeOf</th><th>partOf</th><th>hasParts</th><th>instanceOf</th><th>hasInstances</th><th>memberOf</th><th>hasMembers</th><th>substanceOf</th><th>inCategory</th><th>hasCategories</th><th>regionOf</th><th>zipf</th><th>perMillion</th><th>diversity</th><th>letters</th><th>sounds</th><th>num_definitions</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;aarhus&quot;</td><td>&quot;a port city of Denmark in east…</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;arhus&quot;]</td><td>null</td><td>null</td><td>[&quot;kingdom of denmark&quot;, &quot;danmark&quot;, &quot;denmark&quot;]</td><td>null</td><td>[&quot;metropolis&quot;, &quot;port&quot;, … &quot;city&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.3</td><td>0.19</td><td>0.0</td><td>6</td><td>null</td><td>1</td></tr><tr><td>&quot;abelard&quot;</td><td>&quot;a French philosopher and theol…</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;peter abelard&quot;, &quot;pierre abelard&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>[&quot;philosopher&quot;, &quot;theologian&quot;, … &quot;theologizer&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.82</td><td>0.05</td><td>0.0</td><td>7</td><td>7</td><td>1</td></tr><tr><td>&quot;aborigine&quot;</td><td>&quot;a member of the people living …</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;australian aborigine&quot;, &quot;native australian&quot;]</td><td>null</td><td>[&quot;aussie&quot;, &quot;australian&quot;, … &quot;ethnos&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.49</td><td>0.29</td><td>0.0</td><td>9</td><td>10</td><td>2</td></tr><tr><td>&quot;aborigine&quot;</td><td>&quot;an indigenous person who was b…</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;aboriginal&quot;, &quot;indigen&quot;, … &quot;native&quot;]</td><td>[&quot;russian&quot;, &quot;levantine&quot;, … &quot;filipino&quot;]</td><td>[&quot;soul&quot;, &quot;individual&quot;, … &quot;someone&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.49</td><td>0.29</td><td>0.0</td><td>9</td><td>10</td><td>2</td></tr><tr><td>&quot;acheson&quot;</td><td>&quot;a United States statesman who …</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;dean acheson&quot;, &quot;dean gooderham acheson&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>[&quot;national leader&quot;, &quot;solon&quot;, &quot;statesman&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.2</td><td>0.15</td><td>0.0</td><td>7</td><td>7</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;wtc&quot;</td><td>&quot;a twin skyscrapers 110 stories…</td><td>&quot;noun&quot;</td><td>&quot;FAC&quot;</td><td>[&quot;twin towers&quot;, &quot;world trade center&quot;]</td><td>null</td><td>null</td><td>[&quot;new york city&quot;, &quot;greater new york&quot;, &quot;new york&quot;]</td><td>null</td><td>[&quot;skyscraper&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>[&quot;terrorism&quot;, &quot;terrorist act&quot;, &quot;act of terrorism&quot;]</td><td>null</td><td>null</td><td>3.05</td><td>1.11</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;xtc&quot;</td><td>&quot;a street names for methylenedi…</td><td>&quot;noun&quot;</td><td>&quot;PRODUCT&quot;</td><td>[&quot;adam&quot;, &quot;cristal&quot;, … &quot;x&quot;]</td><td>null</td><td>[&quot;mdma&quot;, &quot;methylenedioxymethamphetamine&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.03</td><td>0.09</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;yisrael&quot;</td><td>&quot;a Jewish republic in southwest…</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;israel&quot;, &quot;sion&quot;, … &quot;zion&quot;]</td><td>null</td><td>null</td><td>[&quot;mideast&quot;, &quot;middle east&quot;, &quot;near east&quot;]</td><td>[&quot;tel aviv-yalo&quot;, &quot;sodom&quot;, … &quot;gomorrah&quot;]</td><td>[&quot;state&quot;, &quot;land&quot;, &quot;country&quot;]</td><td>null</td><td>null</td><td>[&quot;israeli&quot;]</td><td>null</td><td>null</td><td>null</td><td>[&quot;15 may organization&quot;, &quot;a&#x27;man&quot;, … &quot;tanzim&quot;]</td><td>2.57</td><td>0.36</td><td>0.0</td><td>7</td><td>null</td><td>1</td></tr><tr><td>&quot;yue&quot;</td><td>&quot;the dialect of Chinese spoken …</td><td>&quot;noun&quot;</td><td>&quot;LANGUAGE&quot;</td><td>[&quot;cantonese&quot;, &quot;cantonese dialect&quot;, &quot;yue dialect&quot;]</td><td>null</td><td>[&quot;chinese&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.23</td><td>1.69</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;zhou&quot;</td><td>&quot;the imperial dynasty of China …</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;chou&quot;, &quot;chou dynasty&quot;, … &quot;zhou dynasty&quot;]</td><td>null</td><td>[&quot;dynasty&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.41</td><td>2.56</td><td>0.0</td><td>4</td><td>null</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (628, 23)\n",
       "┌───────────┬─────────────┬─────────────┬──────────┬───┬───────────┬─────────┬────────┬────────────┐\n",
       "│ word      ┆ definition  ┆ partOfSpeec ┆ pnoun    ┆ … ┆ diversity ┆ letters ┆ sounds ┆ num_defini │\n",
       "│ ---       ┆ ---         ┆ h           ┆ ---      ┆   ┆ ---       ┆ ---     ┆ ---    ┆ tions      │\n",
       "│ str       ┆ str         ┆ ---         ┆ str      ┆   ┆ f64       ┆ i64     ┆ i64    ┆ ---        │\n",
       "│           ┆             ┆ str         ┆          ┆   ┆           ┆         ┆        ┆ i64        │\n",
       "╞═══════════╪═════════════╪═════════════╪══════════╪═══╪═══════════╪═════════╪════════╪════════════╡\n",
       "│ aarhus    ┆ a port city ┆ noun        ┆ GPE      ┆ … ┆ 0.0       ┆ 6       ┆ null   ┆ 1          │\n",
       "│           ┆ of Denmark  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ in east…    ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ abelard   ┆ a French    ┆ noun        ┆ PERSON   ┆ … ┆ 0.0       ┆ 7       ┆ 7      ┆ 1          │\n",
       "│           ┆ philosopher ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ and theol…  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ aborigine ┆ a member of ┆ noun        ┆ PERSON   ┆ … ┆ 0.0       ┆ 9       ┆ 10     ┆ 2          │\n",
       "│           ┆ the people  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ living …    ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ aborigine ┆ an          ┆ noun        ┆ PERSON   ┆ … ┆ 0.0       ┆ 9       ┆ 10     ┆ 2          │\n",
       "│           ┆ indigenous  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ person who  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ was b…      ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ acheson   ┆ a United    ┆ noun        ┆ PERSON   ┆ … ┆ 0.0       ┆ 7       ┆ 7      ┆ 1          │\n",
       "│           ┆ States      ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ statesman   ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ who …       ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ …         ┆ …           ┆ …           ┆ …        ┆ … ┆ …         ┆ …       ┆ …      ┆ …          │\n",
       "│ wtc       ┆ a twin      ┆ noun        ┆ FAC      ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│           ┆ skyscrapers ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ 110         ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ stories…    ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ xtc       ┆ a street    ┆ noun        ┆ PRODUCT  ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│           ┆ names for   ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ methylenedi ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ …           ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ yisrael   ┆ a Jewish    ┆ noun        ┆ GPE      ┆ … ┆ 0.0       ┆ 7       ┆ null   ┆ 1          │\n",
       "│           ┆ republic in ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ southwest…  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ yue       ┆ the dialect ┆ noun        ┆ LANGUAGE ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│           ┆ of Chinese  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ spoken …    ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ zhou      ┆ the         ┆ noun        ┆ GPE      ┆ … ┆ 0.0       ┆ 4       ┆ null   ┆ 1          │\n",
       "│           ┆ imperial    ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ dynasty of  ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│           ┆ China …     ┆             ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "└───────────┴─────────────┴─────────────┴──────────┴───┴───────────┴─────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.from_dicts(word_list) \n",
    "## Check if PNOUN\n",
    "df = df.with_columns(\n",
    "    pl.struct([\"word\", \"definition\"]).map_elements(lambda x: check_if_pnoun(x[\"word\"], x[\"definition\"]), return_dtype=pl.String).alias(\"pnoun\")\n",
    ")\n",
    "# Reorder columns\n",
    "col_order = [\"word\", \"definition\", \"partOfSpeech\", \"pnoun\", \"synonyms\"] + keywords + [\"zipf\", \"perMillion\", \"diversity\", \"letters\", \"sounds\", \"num_definitions\"]\n",
    "col_order = [col for col in col_order if col in df.columns]\n",
    "df = df.select(col_order)\n",
    "## do some cleaning  (set to null if the PROPN or if adjective or verb)\n",
    "df = df.with_columns(pl.when( (pl.col(\"partOfSpeech\") == \"adjective\") | (pl.col(\"partOfSpeech\") == \"verb\"))\\\n",
    "                .then(None) \\\n",
    "                .otherwise(pl.col(\"pnoun\")) \\\n",
    "                .alias(\"pnoun\")) \\\n",
    "    .with_columns(pl.when(pl.col(\"pnoun\") == \"PROPN\") \\\n",
    "                .then(None) \\\n",
    "                .otherwise(pl.col(\"pnoun\")) \\\n",
    "                .alias(\"pnoun\")) \n",
    "\n",
    "df.write_json(parent_dir + \"/source/definitions.json\")\n",
    "df.sample(20)\n",
    "df.filter(pl.col(\"pnoun\").is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"Statement Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_json(parent_dir + \"/source/definitions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_416, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>word</th><th>definition</th><th>partOfSpeech</th><th>pnoun</th><th>synonyms</th><th>hasTypes</th><th>typeOf</th><th>partOf</th><th>hasParts</th><th>instanceOf</th><th>hasInstances</th><th>memberOf</th><th>hasMembers</th><th>substanceOf</th><th>inCategory</th><th>hasCategories</th><th>regionOf</th><th>zipf</th><th>perMillion</th><th>diversity</th><th>letters</th><th>sounds</th><th>num_definitions</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;aarhus&quot;</td><td>&quot;a port city of Denmark in east…</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;arhus&quot;]</td><td>null</td><td>null</td><td>[&quot;kingdom of denmark&quot;, &quot;danmark&quot;, &quot;denmark&quot;]</td><td>null</td><td>[&quot;metropolis&quot;, &quot;port&quot;, … &quot;city&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.3</td><td>0.19</td><td>0.0</td><td>6</td><td>null</td><td>1</td></tr><tr><td>&quot;abbess&quot;</td><td>&quot;the superior of a group of nun…</td><td>&quot;noun&quot;</td><td>null</td><td>[&quot;mother superior&quot;, &quot;prioress&quot;]</td><td>[&quot;mother&quot;]</td><td>[&quot;superior&quot;]</td><td>null</td><td>null</td><td>null</td><td>[&quot;brigid&quot;, &quot;heloise&quot;, … &quot;bridget&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.47</td><td>0.28</td><td>0.0</td><td>6</td><td>4</td><td>1</td></tr><tr><td>&quot;abelard&quot;</td><td>&quot;a French philosopher and theol…</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;peter abelard&quot;, &quot;pierre abelard&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>[&quot;philosopher&quot;, &quot;theologian&quot;, … &quot;theologizer&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.82</td><td>0.05</td><td>0.0</td><td>7</td><td>7</td><td>1</td></tr><tr><td>&quot;aborigine&quot;</td><td>&quot;a member of the people living …</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;australian aborigine&quot;, &quot;native australian&quot;]</td><td>null</td><td>[&quot;aussie&quot;, &quot;australian&quot;, … &quot;ethnos&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.49</td><td>0.29</td><td>0.0</td><td>9</td><td>10</td><td>2</td></tr><tr><td>&quot;aborigine&quot;</td><td>&quot;an indigenous person who was b…</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;aboriginal&quot;, &quot;indigen&quot;, … &quot;native&quot;]</td><td>[&quot;russian&quot;, &quot;levantine&quot;, … &quot;filipino&quot;]</td><td>[&quot;soul&quot;, &quot;individual&quot;, … &quot;someone&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.49</td><td>0.29</td><td>0.0</td><td>9</td><td>10</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;xtc&quot;</td><td>&quot;a street names for methylenedi…</td><td>&quot;noun&quot;</td><td>&quot;PRODUCT&quot;</td><td>[&quot;adam&quot;, &quot;cristal&quot;, … &quot;x&quot;]</td><td>null</td><td>[&quot;mdma&quot;, &quot;methylenedioxymethamphetamine&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.03</td><td>0.09</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;yisrael&quot;</td><td>&quot;a Jewish republic in southwest…</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;israel&quot;, &quot;sion&quot;, … &quot;zion&quot;]</td><td>null</td><td>null</td><td>[&quot;mideast&quot;, &quot;middle east&quot;, &quot;near east&quot;]</td><td>[&quot;tel aviv-yalo&quot;, &quot;sodom&quot;, … &quot;gomorrah&quot;]</td><td>[&quot;state&quot;, &quot;land&quot;, &quot;country&quot;]</td><td>null</td><td>null</td><td>[&quot;israeli&quot;]</td><td>null</td><td>null</td><td>null</td><td>[&quot;15 may organization&quot;, &quot;a&#x27;man&quot;, … &quot;tanzim&quot;]</td><td>2.57</td><td>0.36</td><td>0.0</td><td>7</td><td>null</td><td>1</td></tr><tr><td>&quot;yue&quot;</td><td>&quot;the dialect of Chinese spoken …</td><td>&quot;noun&quot;</td><td>&quot;LANGUAGE&quot;</td><td>[&quot;cantonese&quot;, &quot;cantonese dialect&quot;, &quot;yue dialect&quot;]</td><td>null</td><td>[&quot;chinese&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.23</td><td>1.69</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;zabaglione&quot;</td><td>&quot;a light foamy custard-like des…</td><td>&quot;noun&quot;</td><td>null</td><td>[&quot;sabayon&quot;]</td><td>null</td><td>[&quot;afters&quot;, &quot;dessert&quot;, &quot;sweet&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.6</td><td>0.03</td><td>0.0</td><td>10</td><td>null</td><td>1</td></tr><tr><td>&quot;zhou&quot;</td><td>&quot;the imperial dynasty of China …</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;chou&quot;, &quot;chou dynasty&quot;, … &quot;zhou dynasty&quot;]</td><td>null</td><td>[&quot;dynasty&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.41</td><td>2.56</td><td>0.0</td><td>4</td><td>null</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_416, 23)\n",
       "┌────────────┬─────────────┬────────────┬──────────┬───┬───────────┬─────────┬────────┬────────────┐\n",
       "│ word       ┆ definition  ┆ partOfSpee ┆ pnoun    ┆ … ┆ diversity ┆ letters ┆ sounds ┆ num_defini │\n",
       "│ ---        ┆ ---         ┆ ch         ┆ ---      ┆   ┆ ---       ┆ ---     ┆ ---    ┆ tions      │\n",
       "│ str        ┆ str         ┆ ---        ┆ str      ┆   ┆ f64       ┆ i64     ┆ i64    ┆ ---        │\n",
       "│            ┆             ┆ str        ┆          ┆   ┆           ┆         ┆        ┆ i64        │\n",
       "╞════════════╪═════════════╪════════════╪══════════╪═══╪═══════════╪═════════╪════════╪════════════╡\n",
       "│ aarhus     ┆ a port city ┆ noun       ┆ GPE      ┆ … ┆ 0.0       ┆ 6       ┆ null   ┆ 1          │\n",
       "│            ┆ of Denmark  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ in east…    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ abbess     ┆ the         ┆ noun       ┆ null     ┆ … ┆ 0.0       ┆ 6       ┆ 4      ┆ 1          │\n",
       "│            ┆ superior of ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ a group of  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ nun…        ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ abelard    ┆ a French    ┆ noun       ┆ PERSON   ┆ … ┆ 0.0       ┆ 7       ┆ 7      ┆ 1          │\n",
       "│            ┆ philosopher ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ and theol…  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ aborigine  ┆ a member of ┆ noun       ┆ PERSON   ┆ … ┆ 0.0       ┆ 9       ┆ 10     ┆ 2          │\n",
       "│            ┆ the people  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ living …    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ aborigine  ┆ an          ┆ noun       ┆ PERSON   ┆ … ┆ 0.0       ┆ 9       ┆ 10     ┆ 2          │\n",
       "│            ┆ indigenous  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ person who  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ was b…      ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ …          ┆ …           ┆ …          ┆ …        ┆ … ┆ …         ┆ …       ┆ …      ┆ …          │\n",
       "│ xtc        ┆ a street    ┆ noun       ┆ PRODUCT  ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│            ┆ names for   ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ methylenedi ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ …           ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ yisrael    ┆ a Jewish    ┆ noun       ┆ GPE      ┆ … ┆ 0.0       ┆ 7       ┆ null   ┆ 1          │\n",
       "│            ┆ republic in ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ southwest…  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ yue        ┆ the dialect ┆ noun       ┆ LANGUAGE ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│            ┆ of Chinese  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ spoken …    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ zabaglione ┆ a light     ┆ noun       ┆ null     ┆ … ┆ 0.0       ┆ 10      ┆ null   ┆ 1          │\n",
       "│            ┆ foamy custa ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ rd-like     ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ des…        ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ zhou       ┆ the         ┆ noun       ┆ GPE      ┆ … ┆ 0.0       ┆ 4       ┆ null   ┆ 1          │\n",
       "│            ┆ imperial    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ dynasty of  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ China …     ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "└────────────┴─────────────┴────────────┴──────────┴───┴───────────┴─────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "\n",
    "def is_plural(word):\n",
    "    \"\"\"\n",
    "    Check if a word is plural\n",
    "    \"\"\"\n",
    "    word = word.split(' ')[0]\n",
    "    check = p.singular_noun(word)\n",
    "    if type(check) == str:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_035, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>word</th><th>definition</th><th>partOfSpeech</th><th>pnoun</th><th>synonyms</th><th>hasTypes</th><th>typeOf</th><th>partOf</th><th>hasParts</th><th>instanceOf</th><th>hasInstances</th><th>memberOf</th><th>hasMembers</th><th>substanceOf</th><th>inCategory</th><th>hasCategories</th><th>regionOf</th><th>zipf</th><th>perMillion</th><th>diversity</th><th>letters</th><th>sounds</th><th>num_definitions</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;aarhus&quot;</td><td>&quot;a port city of Denmark in east…</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;arhus&quot;]</td><td>null</td><td>null</td><td>[&quot;kingdom of denmark&quot;, &quot;danmark&quot;, &quot;denmark&quot;]</td><td>null</td><td>[&quot;metropolis&quot;, &quot;port&quot;, … &quot;city&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.3</td><td>0.19</td><td>0.0</td><td>6</td><td>null</td><td>1</td></tr><tr><td>&quot;abbess&quot;</td><td>&quot;the superior of a group of nun…</td><td>&quot;noun&quot;</td><td>null</td><td>[&quot;mother superior&quot;, &quot;prioress&quot;]</td><td>[&quot;mother&quot;]</td><td>[&quot;superior&quot;]</td><td>null</td><td>null</td><td>null</td><td>[&quot;brigid&quot;, &quot;heloise&quot;, … &quot;bridget&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.47</td><td>0.28</td><td>0.0</td><td>6</td><td>4</td><td>1</td></tr><tr><td>&quot;abelard&quot;</td><td>&quot;a French philosopher and theol…</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;peter abelard&quot;, &quot;pierre abelard&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>[&quot;philosopher&quot;, &quot;theologian&quot;, … &quot;theologizer&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.82</td><td>0.05</td><td>0.0</td><td>7</td><td>7</td><td>1</td></tr><tr><td>&quot;aborigine&quot;</td><td>&quot;a member of the people living …</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;australian aborigine&quot;, &quot;native australian&quot;]</td><td>null</td><td>[&quot;aussie&quot;, &quot;australian&quot;, … &quot;ethnos&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.49</td><td>0.29</td><td>0.0</td><td>9</td><td>10</td><td>2</td></tr><tr><td>&quot;aborigine&quot;</td><td>&quot;an indigenous person who was b…</td><td>&quot;noun&quot;</td><td>&quot;PERSON&quot;</td><td>[&quot;aboriginal&quot;, &quot;indigen&quot;, … &quot;native&quot;]</td><td>[&quot;russian&quot;, &quot;levantine&quot;, … &quot;filipino&quot;]</td><td>[&quot;soul&quot;, &quot;individual&quot;, … &quot;someone&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.49</td><td>0.29</td><td>0.0</td><td>9</td><td>10</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;XTC&quot;</td><td>&quot;a street names for methylenedi…</td><td>&quot;noun&quot;</td><td>&quot;PRODUCT&quot;</td><td>[&quot;adam&quot;, &quot;cristal&quot;, … &quot;x&quot;]</td><td>null</td><td>[&quot;mdma&quot;, &quot;methylenedioxymethamphetamine&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.03</td><td>0.09</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;yisrael&quot;</td><td>&quot;a Jewish republic in southwest…</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;israel&quot;, &quot;sion&quot;, … &quot;zion&quot;]</td><td>null</td><td>null</td><td>[&quot;mideast&quot;, &quot;middle east&quot;, &quot;near east&quot;]</td><td>[&quot;tel aviv-yalo&quot;, &quot;sodom&quot;, … &quot;gomorrah&quot;]</td><td>[&quot;state&quot;, &quot;land&quot;, &quot;country&quot;]</td><td>null</td><td>null</td><td>[&quot;israeli&quot;]</td><td>null</td><td>null</td><td>null</td><td>[&quot;15 may organization&quot;, &quot;a&#x27;man&quot;, … &quot;tanzim&quot;]</td><td>2.57</td><td>0.36</td><td>0.0</td><td>7</td><td>null</td><td>1</td></tr><tr><td>&quot;yue&quot;</td><td>&quot;the dialect of Chinese spoken …</td><td>&quot;noun&quot;</td><td>&quot;LANGUAGE&quot;</td><td>[&quot;cantonese&quot;, &quot;cantonese dialect&quot;, &quot;yue dialect&quot;]</td><td>null</td><td>[&quot;chinese&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.23</td><td>1.69</td><td>0.0</td><td>3</td><td>null</td><td>1</td></tr><tr><td>&quot;zabaglione&quot;</td><td>&quot;a light foamy custard-like des…</td><td>&quot;noun&quot;</td><td>null</td><td>[&quot;sabayon&quot;]</td><td>null</td><td>[&quot;afters&quot;, &quot;dessert&quot;, &quot;sweet&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.6</td><td>0.03</td><td>0.0</td><td>10</td><td>null</td><td>1</td></tr><tr><td>&quot;zhou&quot;</td><td>&quot;the imperial dynasty of China …</td><td>&quot;noun&quot;</td><td>&quot;GPE&quot;</td><td>[&quot;chou&quot;, &quot;chou dynasty&quot;, … &quot;zhou dynasty&quot;]</td><td>null</td><td>[&quot;dynasty&quot;]</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.41</td><td>2.56</td><td>0.0</td><td>4</td><td>null</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_035, 23)\n",
       "┌────────────┬─────────────┬────────────┬──────────┬───┬───────────┬─────────┬────────┬────────────┐\n",
       "│ word       ┆ definition  ┆ partOfSpee ┆ pnoun    ┆ … ┆ diversity ┆ letters ┆ sounds ┆ num_defini │\n",
       "│ ---        ┆ ---         ┆ ch         ┆ ---      ┆   ┆ ---       ┆ ---     ┆ ---    ┆ tions      │\n",
       "│ str        ┆ str         ┆ ---        ┆ str      ┆   ┆ f64       ┆ i64     ┆ i64    ┆ ---        │\n",
       "│            ┆             ┆ str        ┆          ┆   ┆           ┆         ┆        ┆ i64        │\n",
       "╞════════════╪═════════════╪════════════╪══════════╪═══╪═══════════╪═════════╪════════╪════════════╡\n",
       "│ aarhus     ┆ a port city ┆ noun       ┆ GPE      ┆ … ┆ 0.0       ┆ 6       ┆ null   ┆ 1          │\n",
       "│            ┆ of Denmark  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ in east…    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ abbess     ┆ the         ┆ noun       ┆ null     ┆ … ┆ 0.0       ┆ 6       ┆ 4      ┆ 1          │\n",
       "│            ┆ superior of ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ a group of  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ nun…        ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ abelard    ┆ a French    ┆ noun       ┆ PERSON   ┆ … ┆ 0.0       ┆ 7       ┆ 7      ┆ 1          │\n",
       "│            ┆ philosopher ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ and theol…  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ aborigine  ┆ a member of ┆ noun       ┆ PERSON   ┆ … ┆ 0.0       ┆ 9       ┆ 10     ┆ 2          │\n",
       "│            ┆ the people  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ living …    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ aborigine  ┆ an          ┆ noun       ┆ PERSON   ┆ … ┆ 0.0       ┆ 9       ┆ 10     ┆ 2          │\n",
       "│            ┆ indigenous  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ person who  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ was b…      ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ …          ┆ …           ┆ …          ┆ …        ┆ … ┆ …         ┆ …       ┆ …      ┆ …          │\n",
       "│ XTC        ┆ a street    ┆ noun       ┆ PRODUCT  ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│            ┆ names for   ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ methylenedi ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ …           ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ yisrael    ┆ a Jewish    ┆ noun       ┆ GPE      ┆ … ┆ 0.0       ┆ 7       ┆ null   ┆ 1          │\n",
       "│            ┆ republic in ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ southwest…  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ yue        ┆ the dialect ┆ noun       ┆ LANGUAGE ┆ … ┆ 0.0       ┆ 3       ┆ null   ┆ 1          │\n",
       "│            ┆ of Chinese  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ spoken …    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ zabaglione ┆ a light     ┆ noun       ┆ null     ┆ … ┆ 0.0       ┆ 10      ┆ null   ┆ 1          │\n",
       "│            ┆ foamy custa ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ rd-like     ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ des…        ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│ zhou       ┆ the         ┆ noun       ┆ GPE      ┆ … ┆ 0.0       ┆ 4       ┆ null   ┆ 1          │\n",
       "│            ┆ imperial    ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ dynasty of  ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "│            ┆ China …     ┆            ┆          ┆   ┆           ┆         ┆        ┆            │\n",
       "└────────────┴─────────────┴────────────┴──────────┴───┴───────────┴─────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_upper = ['ORG', 'FAC', 'GPE', 'PRODUCT']\n",
    "words2filter = pl.Series(['terrorist', 'terrorist group'])\n",
    "df = (\n",
    "    pl.read_json(parent_dir + \"/source/definitions.json\")\n",
    "    .filter(pl.col(\"partOfSpeech\") == \"noun\")\n",
    "    # .filter(~pl.col('typeOf').list.contains(words2filter))\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"pnoun\").is_in(to_upper) & (pl.col(\"word\").str.len_chars() < 4))\n",
    "          .then(pl.col(\"word\").str.to_uppercase())\n",
    "          .otherwise(pl.col(\"word\"))\n",
    "          .alias(\"word\")\n",
    "    )\n",
    ")\n",
    "df = df.filter(~pl.col('instanceOf').list.contains('terrorist group') & ~pl.col('instanceOf').list.contains('terrorist') \\\n",
    "          & ~pl.col('instanceOf').list.contains('weapon') & ~pl.col('instanceOf').list.contains('ammunition') \\\n",
    "          &  ~pl.col('instanceOf').list.contains('firearm') & ~pl.col('instanceOf').list.contains('toxin'))\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = dict(df.select(\"word\", \"zipf\").iter_rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 1262, 1028)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instanceOf = dict(df.filter(pl.col(\"instanceOf\").is_not_null()).select(['word', 'instanceOf']).iter_rows())\n",
    "typeOf = dict(df.filter(pl.col(\"typeOf\").is_not_null()).select(['word', 'typeOf']).iter_rows())\n",
    "synonyms = dict(df.filter(pl.col(\"synonyms\").is_not_null() & pl.col('pnoun').is_null()).select(['word', 'synonyms']).iter_rows())\n",
    "len(instanceOf), len(typeOf), len(synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsInstances(DatasetGenerator):\n",
    "    '''\n",
    "    Class to handle the dataset from WordAPI\n",
    "    '''    \n",
    "    def apply_template(self, word: str, definition: str, negated: bool=False):\n",
    "        if word.upper() == word:\n",
    "            word = word\n",
    "        else:\n",
    "            word = word.capitalize()\n",
    "        if not is_plural(definition):\n",
    "            definition = p.a(definition)\n",
    "        if negated:\n",
    "            return f\"{word} is not {definition}.\"\n",
    "        else:\n",
    "            return f\"{word} is {definition}.\"\n",
    "    \n",
    "\n",
    "    def generate_sample(self, key, value, negated: bool):\n",
    "        correct_values = self.source[key]\n",
    "        correct = any([value.lower() in v.lower() for v in correct_values])\n",
    "        if negated:\n",
    "            correct = not correct\n",
    "        if not self.is_fake:\n",
    "            return {'statement': self.apply_template(key, value, negated),\n",
    "                    'object_1': key,\n",
    "                    'object_2': value,\n",
    "                    'correct_object_2':  correct_values,\n",
    "                    'correct': correct,\n",
    "                    'negated': negated,\n",
    "                    'real_object': True,\n",
    "                    'fake_object': False,\n",
    "                    'fictional_object': False,\n",
    "                    'category': self.category,\n",
    "                    }\n",
    "        else:\n",
    "            return {'statement': self.apply_template(key, value, negated),\n",
    "                    'object_1': key,\n",
    "                    'object_2': value,\n",
    "                    # correct_values do notmean anything in this case\n",
    "                    'correct_object_2':  correct_values,\n",
    "                    'correct': False,\n",
    "                    'negated': negated,\n",
    "                    'real_object': False,\n",
    "                    'fake_object': True,\n",
    "                    'fictional_object': False,\n",
    "                    'category': self.category\n",
    "                    }\n",
    "\n",
    "        \n",
    "    def generate_subsample(self, n: int, seed: int, objects: list = None):\n",
    "        np.random.seed(seed)\n",
    "        if objects is not None:\n",
    "            data = self.data.filter(pl.col(\"object_1\").is_in(objects))\n",
    "        else:\n",
    "            data = self.data\n",
    "        if data.height > n:\n",
    "            print(f'Downsample from {data.height} to {n}')\n",
    "            data = data.sample(n, seed=seed, shuffle=True)\n",
    "        else:\n",
    "            print(f'Size of the dataset is {data.height}')\n",
    "        return data\n",
    "\n",
    "\n",
    "class WordsTypes(WordsInstances):\n",
    "    '''\n",
    "    Class to handle the dataset from WordAPI\n",
    "    '''    \n",
    "    def apply_template(self, word: str, definition: str, negated: bool=False):\n",
    "        if word.upper() == word:\n",
    "            word = word\n",
    "        else:\n",
    "            word = word.capitalize()\n",
    "        if not is_plural(definition):\n",
    "            definition = p.a(definition)\n",
    "        if negated:\n",
    "            return f\"{word.capitalize()} is not a type of {definition}.\"\n",
    "        else:\n",
    "            return f\"{word.capitalize()} is a type of {definition}.\"\n",
    "\n",
    "    \n",
    "db_inst = WordsInstances(instanceOf, category='instances')\n",
    "data_inst = db_inst.generate_full_dataset()\n",
    "data_inst.write_json(f\"{parent_dir}/source/word_instances.json\")\n",
    "db_type = WordsTypes(typeOf, category='types')\n",
    "data_type = db_type.generate_full_dataset()\n",
    "data_type.write_json(f\"{parent_dir}/source/word_types.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsSynonyms(WordsInstances):\n",
    "    '''\n",
    "    Class to handle the dataset from WordAPI\n",
    "    '''    \n",
    "    def apply_template(self, word: str, definition: str, negated: bool=False):\n",
    "        if word.upper() == word:\n",
    "            word = word\n",
    "        else:\n",
    "            word = word.capitalize()\n",
    "        if not is_plural(definition):\n",
    "            definition = p.a(definition)\n",
    "        if negated:\n",
    "            return f\"{word.capitalize()} is not a synonym of {definition}.\"\n",
    "        else:\n",
    "            return f\"{word.capitalize()} is a synonym of {definition}.\"\n",
    "\n",
    "    \n",
    "db_synonym = WordsSynonyms(synonyms, category='synonyms')\n",
    "data_synonym = db_synonym.generate_full_dataset()\n",
    "data_synonym.write_json(f\"{parent_dir}/source/word_synonyms.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1492, 1447)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "def get_zipf(word):\n",
    "    return zipf_frequency(word, 'en')\n",
    "\n",
    "objects = list(set(db_inst.keys + db_type.keys + db_synonym.keys))\n",
    "objects_validated = [word for word in objects if get_zipf(word) > 0]\n",
    "len(objects), len(objects_validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample from 1352 to 1000\n",
      "Downsample from 5960 to 2000\n",
      "Downsample from 5008 to 2000\n"
     ]
    }
   ],
   "source": [
    "objects = set(db_inst.keys + db_type.keys + db_synonym.keys)\n",
    "objects = np.random.choice(list(objects), 800, replace=False)\n",
    "subsample_inst = db_inst.generate_subsample(1000, 42, objects).with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample_inst.write_csv(f\"{parent_dir}/word_instances_subsample.csv\")\n",
    "subsample_types = db_type.generate_subsample(2000, 42, objects=objects).with_columns(\n",
    "                 pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample_types.write_csv(f\"{parent_dir}/word_types_subsample.csv\")\n",
    "\n",
    "subsample_synonyms = db_synonym.generate_subsample(2000, 42, objects=objects).with_columns(\n",
    "                    pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "subsample_synonyms.write_csv(f\"{parent_dir}/word_synonyms_subsample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_43290/2847185386.py:1: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  subsample_inst.vstack(subsample_types).vstack(subsample_synonyms).group_by(['correct', 'negated']).count()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>correct</th><th>negated</th><th>count</th></tr><tr><td>bool</td><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>true</td><td>false</td><td>1269</td></tr><tr><td>false</td><td>false</td><td>1223</td></tr><tr><td>true</td><td>true</td><td>1251</td></tr><tr><td>false</td><td>true</td><td>1257</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌─────────┬─────────┬───────┐\n",
       "│ correct ┆ negated ┆ count │\n",
       "│ ---     ┆ ---     ┆ ---   │\n",
       "│ bool    ┆ bool    ┆ u32   │\n",
       "╞═════════╪═════════╪═══════╡\n",
       "│ true    ┆ false   ┆ 1269  │\n",
       "│ false   ┆ false   ┆ 1223  │\n",
       "│ true    ┆ true    ┆ 1251  │\n",
       "│ false   ┆ true    ┆ 1257  │\n",
       "└─────────┴─────────┴───────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample_inst.vstack(subsample_types).vstack(subsample_synonyms).group_by(['correct', 'negated']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from english_words import get_english_words_set\n",
    "web_words = get_english_words_set(['web2'], lower=True)\n",
    "gcide_words = get_english_words_set(['gcide'], lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/carlomarx/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "english_words = set(words.words())\n",
    "\n",
    "def check_if_exists(word):\n",
    "    if word in english_words:\n",
    "        return True\n",
    "    if word.lower() in web_words:\n",
    "        return True\n",
    "    if word.lower() in gcide_words:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_if_full_exists(phrase):\n",
    "    return all([check_if_exists(word) for word in phrase.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_exists(\"owenster\"), check_if_full_exists('boaok cover'), check_if_full_exists('book cover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from namemaker import NameSet\n",
    "import namemaker\n",
    "\n",
    "seed = 'udaxihhexdvxrcsnbacghqtargwuwr'\n",
    "random.seed(seed)\n",
    "namemaker_rng = namemaker.get_rng()\n",
    "namemaker_rng.seed(seed)\n",
    "\n",
    "our_vocab = sorted(df['word'].unique().to_list())\n",
    "word_NS = NameSet(names = our_vocab)\n",
    "word_synth = [word_NS.make_name(add_to_history=False) for _ in range(1000)]\n",
    "word_synth = list(set(word_synth))\n",
    "# Validate\n",
    "word_validated = []\n",
    "for item in word_synth:\n",
    "    if not check_if_exists(item):\n",
    "        word_validated.append(item)\n",
    "    else:\n",
    "        pass\n",
    "with open(f\"{parent_dir}/source/synth_words.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, word_validated)))\n",
    "\n",
    "inst_vocab = set(db_inst.values).union(set(our_vocab))\n",
    "inst_NS = NameSet(names = inst_vocab)\n",
    "inst_synth = [inst_NS.make_name(add_to_history=False) for _ in range(1000)]\n",
    "inst_synth = list(set(inst_synth))\n",
    "inst_validated = []\n",
    "for item in inst_synth:\n",
    "    if not check_if_full_exists(item):\n",
    "        inst_validated.append(item)\n",
    "    else:\n",
    "        pass\n",
    "with open(f\"{parent_dir}/source/word_synth_inst.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, inst_validated)))\n",
    "\n",
    "type_vocab = set(db_type.values).union(set(our_vocab))\n",
    "type_NS = NameSet(names = type_vocab)\n",
    "type_synth = [type_NS.make_name(add_to_history=False) for _ in range(1000)]\n",
    "type_synth = list(set(type_synth))\n",
    "type_validated = []\n",
    "for item in type_synth:\n",
    "    if not check_if_full_exists(item):\n",
    "        type_validated.append(item)\n",
    "    else:\n",
    "        pass\n",
    "with open(f\"{parent_dir}/source/word_synth_type.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, type_validated)))\n",
    "\n",
    "\n",
    "synonyms_vocab = set(db_synonym.values).union(set(our_vocab))\n",
    "synonyms_NS = NameSet(names = synonyms_vocab)\n",
    "synonyms_synth = [synonyms_NS.make_name(add_to_history=False) for _ in range(1000)]\n",
    "synonyms_synth = list(set(synonyms_synth))\n",
    "synonyms_validated = []\n",
    "for item in synonyms_synth:\n",
    "    if not check_if_full_exists(item):\n",
    "        synonyms_validated.append(item)\n",
    "    else:\n",
    "        pass\n",
    "with open(f\"{parent_dir}/source/word_synth_synonyms.txt\", 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, synonyms_validated)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample from 6600 to 500\n"
     ]
    }
   ],
   "source": [
    "synth_word2inst = {}\n",
    "for item in word_validated:\n",
    "    synth_word2inst[item] = random.sample(inst_validated, 2)\n",
    "db_syn_word2inst = WordsInstances(synth_word2inst, category='instances', is_fake=True)\n",
    "data_syn_word2inst = db_syn_word2inst.generate_full_dataset()\n",
    "data_syn_word2inst.write_json(f\"{parent_dir}/source/synth_word2inst.json\")\n",
    "\n",
    "data_syn_word2inst = db_syn_word2inst.generate_subsample(500, 42).with_columns(\n",
    "                    pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "data_syn_word2inst.write_csv(f\"{parent_dir}/synth_word2inst_subsample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample from 6600 to 1500\n"
     ]
    }
   ],
   "source": [
    "synth_word2type = {}\n",
    "for item in word_validated:\n",
    "    synth_word2type[item] = random.sample(type_validated, 2)\n",
    "db_syn_word2type = WordsTypes(synth_word2type, category='types', is_fake=True)\n",
    "data_syn_word2type = db_syn_word2type.generate_full_dataset()\n",
    "data_syn_word2type.write_json(f\"{parent_dir}/source/synth_word2type.json\")\n",
    "\n",
    "data_syn_word2type = db_syn_word2type.generate_subsample(1500, 42).with_columns(\n",
    "                    pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "data_syn_word2type.write_csv(f\"{parent_dir}/synth_word2type_subsample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample from 6600 to 1500\n"
     ]
    }
   ],
   "source": [
    "synth_word2syn = {}\n",
    "for item in word_validated:\n",
    "    synth_word2syn[item] = random.sample(synonyms_validated, 2)\n",
    "db_syn_word2syn = WordsSynonyms(synth_word2syn, category='synonyms', is_fake=True)\n",
    "data_syn_word2syn = db_syn_word2syn.generate_full_dataset()\n",
    "data_syn_word2syn.write_json(f\"{parent_dir}/source/synth_word2syn.json\")\n",
    "\n",
    "data_syn_word2syn = db_syn_word2syn.generate_subsample(1500, 42).with_columns(\n",
    "                    pl.col(\"correct_object_2\").list.join(\", \").alias(\"correct_object_2\"))\n",
    "data_syn_word2syn.write_csv(f\"{parent_dir}/synth_word2syn_subsample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/3vzybg253k1d3n7qzxkts_2c0000gn/T/ipykernel_25742/2981686669.py:1: DeprecationWarning: `GroupBy.count` is deprecated. It has been renamed to `len`.\n",
      "  data_syn_word2inst.vstack(data_syn_word2type).vstack(data_syn_word2syn).group_by(['correct', 'negated']).count()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>correct</th><th>negated</th><th>count</th></tr><tr><td>bool</td><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>false</td><td>true</td><td>1753</td></tr><tr><td>false</td><td>false</td><td>1747</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌─────────┬─────────┬───────┐\n",
       "│ correct ┆ negated ┆ count │\n",
       "│ ---     ┆ ---     ┆ ---   │\n",
       "│ bool    ┆ bool    ┆ u32   │\n",
       "╞═════════╪═════════╪═══════╡\n",
       "│ false   ┆ true    ┆ 1753  │\n",
       "│ false   ┆ false   ┆ 1747  │\n",
       "└─────────┴─────────┴───────┘"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_syn_word2inst.vstack(data_syn_word2type).vstack(data_syn_word2syn).group_by(['correct', 'negated']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fictional_words = {\n",
    "    \"Zorfling\": \"the act of jumping between realities within the same multiverse.\",\n",
    "    \"Plimble\": \"a small, whimsical creature known for its love of shiny objects.\",\n",
    "    \"Glavish\": \"a melodic sound produced by the wind passing through a specific type of hollow tree.\",\n",
    "    \"Crabunk\": \"a feeling of sudden joy experienced when solving a complex problem.\",\n",
    "    \"Nexlore\": \"an ancient, forgotten language that was once spoken by a now-extinct civilization.\",\n",
    "    \"Mirdlewomp\": \"a mysterious, enchanted forest said to exist in the northern reaches of the world.\",\n",
    "    \"Swizzle\": \"a type of magical potion that changes color based on the drinker's mood.\",\n",
    "    \"Jorflap\": \"an intricate dance performed during the Festival of Lights.\",\n",
    "    \"Klibber\": \"a rare and precious stone that glows softly in the dark.\",\n",
    "    \"Frozbloom\": \"a flower that only blooms during a lunar eclipse.\",\n",
    "    \"Grimble\": \"a wise elder who serves as a mentor in a community.\",\n",
    "    \"Sparvile\": \"to swiftly and elegantly maneuver through a crowded space.\",\n",
    "    \"Dralic\": \"a legendary beast known for its strength and benevolence.\",\n",
    "    \"Quinthor\": \"a game played by the ancients, involving strategy and skill, similar to chess.\",\n",
    "    \"Wistlawn\": \"a tranquil meadow where magical creatures are said to gather.\",\n",
    "    \"Jimboree\": \"a large, joyful gathering of friends and family, often involving music and dance.\",\n",
    "    \"Klottish\": \"the state of being slightly disoriented or confused.\",\n",
    "    \"Brindlequack\": \"a peculiar bird known for its colorful plumage and distinctive call.\",\n",
    "    \"Thramble\": \"the sensation of tingling warmth experienced when holding hands with a loved one.\",\n",
    "    \"Xyro\": \"a powerful spell used to summon protective spirits.\",\n",
    "    \"Yafflem\": \"an ancient scroll containing knowledge lost to time.\",\n",
    "    \"Blunderbussle\": \"a clumsy but endearing person who often finds themselves in amusing predicaments.\",\n",
    "    \"Cringle\": \"the sound of laughter carried on a breeze.\",\n",
    "    \"Frozzle\": \"to mix a tea with precise and delicate movements.\",\n",
    "    \"Harrowheel\": \"a child known for their unwavering courage and determination.\",\n",
    "    \"Inkwisp\": \"a mother figure that appears to guide lost travelers.\",\n",
    "    \"Jubilark\": \"a state of overwhelming happiness and contentment.\",\n",
    "    \"Lurvish\": \"the act of whispering sweet nothings to a romantic partner.\",\n",
    "    \"Mizzletop\": \"the highest point of a mountain, often shrouded in mist.\",\n",
    "    \"Nimbletree\": \"a tree known for its agility and ability to move slightly to avoid danger.\",\n",
    "    \"Quizzik\": \"an ancient riddle that has never been solved.\",\n",
    "    \"Rafflenook\": \"a cozy corner in a library filled with rare and old books.\",\n",
    "    \"Snizzle\": \"to giggle quietly to oneself.\",\n",
    "    \"Umbrafrost\": \"a frost that appears only under a full moon.\",\n",
    "    \"Vespervine\": \"a vine that blooms only at dusk and only when looked at.\",\n",
    "    \"Whimsywood\": \"a forest where anything is possible.\",\n",
    "    \"Xylith\": \"a rare mineral that only exists under the schools.\",\n",
    "    \"Yonderwisp\": \"a distant, flickering light that guides mice to their destination.\",\n",
    "    \"Zephyrine\": \"a gentle breeze that carries a hint of garlic.\",\n",
    "    \"Blithery\": \"to speak with great excitement and enthusiasm.\",\n",
    "    \"Dromik\": \"a fast and agile creature known for its keen sense of direction.\",\n",
    "    \"Jaxel\": \"a playful spirit that brings joy and laughter.\",\n",
    "    \"Klimora\": \"the ancient, hidden city known for its advanced technology and wisdom.\",\n",
    "    \"Flumplen\": \"a feeling of joyful confusion.\",\n",
    "    \"Snurfle\": \"to engage in a friendly struggle.\",\n",
    "    \"Jinkle\": \"a small, shiny object that brings good luck.\",\n",
    "    \"Wuggle\": \"to walk with an unsteady gait.\",\n",
    "    \"Klabloom\": \"a type of rare, exotic flower.\",\n",
    "    \"Flimbul\": \"a type of delicate, sparkling fabric.\",\n",
    "    \"Jinklewiff\": \"a playful, mischievous spirit.\",\n",
    "    \"Wumplen\": \"to stumble or trip.\",\n",
    "    \"Klabber\": \"a type of sticky, sweet substance.\",\n",
    "    \"Flarglepunk\": \"the style of music characterized by lively rhythms.\",\n",
    "    \"Snurflebug\": \"the small, insect-like creature.\",\n",
    "    \"Flumplenux\": \"the complex problem or puzzle.\",\n",
    "    \"Snazzlefrazz\": \"a stylish, fashionable outfit.\",\n",
    "    \"Jinkleplack\": \"a type of rare, precious metal.\",\n",
    "    \"Flargleplex\": \"the complicated, confusing situation.\",\n",
    "    \"Jabberton\": \"a talkative, chatty person.\",\n",
    "    \"Kabloinga\": \"a sudden, unexpected event.\",\n",
    "    \"Flimbulux\": \"a delicate, intricate mechanism.\",\n",
    "    \"Ignigen\": \"a creature born from fire.\",\n",
    "    \"Jovialix\": \"a plant that laughs when touched.\",\n",
    "    \"Kinetibar\": \"a bar that serves only energy drinks.\",\n",
    "    \"Elysianth\": \"a flower that blooms in paradise.\",\n",
    "    \"Hydrocera\": \"a wax that repels water, oil and air.\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statement</th><th>object_1</th><th>object_2</th><th>correct_object_2</th><th>correct</th><th>negation</th><th>real_object</th><th>fictional_object</th><th>fake_object</th><th>category</th><th>freq</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Zorfling is de…</td><td>&quot;Zorfling&quot;</td><td>&quot;the act of jum…</td><td>&quot;the act of jum…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>&quot;definition&quot;</td><td>0</td></tr><tr><td>&quot;Zorfling is no…</td><td>&quot;Zorfling&quot;</td><td>&quot;the act of jum…</td><td>&quot;the act of jum…</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>&quot;definition&quot;</td><td>0</td></tr><tr><td>&quot;Plimble can be…</td><td>&quot;Plimble&quot;</td><td>&quot;a small, whims…</td><td>&quot;a small, whims…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>&quot;definition&quot;</td><td>0</td></tr><tr><td>&quot;A small, whims…</td><td>&quot;Plimble&quot;</td><td>&quot;a small, whims…</td><td>&quot;a small, whims…</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>&quot;definition&quot;</td><td>0</td></tr><tr><td>&quot;A melodic soun…</td><td>&quot;Glavish&quot;</td><td>&quot;a melodic soun…</td><td>&quot;a melodic soun…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>&quot;definition&quot;</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌────────────┬──────────┬────────────┬────────────┬───┬────────────┬────────────┬───────────┬──────┐\n",
       "│ statement  ┆ object_1 ┆ object_2   ┆ correct_ob ┆ … ┆ fictional_ ┆ fake_objec ┆ category  ┆ freq │\n",
       "│ ---        ┆ ---      ┆ ---        ┆ ject_2     ┆   ┆ object     ┆ t          ┆ ---       ┆ ---  │\n",
       "│ str        ┆ str      ┆ str        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ str       ┆ i64  │\n",
       "│            ┆          ┆            ┆ str        ┆   ┆ i64        ┆ i64        ┆           ┆      │\n",
       "╞════════════╪══════════╪════════════╪════════════╪═══╪════════════╪════════════╪═══════════╪══════╡\n",
       "│ Zorfling   ┆ Zorfling ┆ the act of ┆ the act of ┆ … ┆ 0          ┆ 1          ┆ definitio ┆ 0    │\n",
       "│ is defined ┆          ┆ jumping    ┆ jumping    ┆   ┆            ┆            ┆ n         ┆      │\n",
       "│ as the act ┆          ┆ between    ┆ between    ┆   ┆            ┆            ┆           ┆      │\n",
       "│ o…         ┆          ┆ reali…     ┆ reali…     ┆   ┆            ┆            ┆           ┆      │\n",
       "│ Zorfling   ┆ Zorfling ┆ the act of ┆ the act of ┆ … ┆ 0          ┆ 1          ┆ definitio ┆ 0    │\n",
       "│ is not     ┆          ┆ jumping    ┆ jumping    ┆   ┆            ┆            ┆ n         ┆      │\n",
       "│ defined as ┆          ┆ between    ┆ between    ┆   ┆            ┆            ┆           ┆      │\n",
       "│ the a…     ┆          ┆ reali…     ┆ reali…     ┆   ┆            ┆            ┆           ┆      │\n",
       "│ Plimble    ┆ Plimble  ┆ a small,   ┆ a small,   ┆ … ┆ 0          ┆ 1          ┆ definitio ┆ 0    │\n",
       "│ can be int ┆          ┆ whimsical  ┆ whimsical  ┆   ┆            ┆            ┆ n         ┆      │\n",
       "│ erpreted   ┆          ┆ creature   ┆ creature   ┆   ┆            ┆            ┆           ┆      │\n",
       "│ as a …     ┆          ┆ know…      ┆ know…      ┆   ┆            ┆            ┆           ┆      │\n",
       "│ A small,   ┆ Plimble  ┆ a small,   ┆ a small,   ┆ … ┆ 0          ┆ 1          ┆ definitio ┆ 0    │\n",
       "│ whimsical  ┆          ┆ whimsical  ┆ whimsical  ┆   ┆            ┆            ┆ n         ┆      │\n",
       "│ creature   ┆          ┆ creature   ┆ creature   ┆   ┆            ┆            ┆           ┆      │\n",
       "│ know…      ┆          ┆ know…      ┆ know…      ┆   ┆            ┆            ┆           ┆      │\n",
       "│ A melodic  ┆ Glavish  ┆ a melodic  ┆ a melodic  ┆ … ┆ 0          ┆ 1          ┆ definitio ┆ 0    │\n",
       "│ sound      ┆          ┆ sound      ┆ sound      ┆   ┆            ┆            ┆ n         ┆      │\n",
       "│ produced   ┆          ┆ produced   ┆ produced   ┆   ┆            ┆            ┆           ┆      │\n",
       "│ by the …   ┆          ┆ by the …   ┆ by the …   ┆   ┆            ┆            ┆           ┆      │\n",
       "└────────────┴──────────┴────────────┴────────────┴───┴────────────┴────────────┴───────────┴──────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"statement\", \"object_1\", \"object_2\", \"correct_object_2\", \"correct\", \"negation\", \"real_object\", \"fictional_object\", \"fake_object\", \"category\", \"freq\"]\n",
    "rows = []\n",
    "fictional_definitions = list(fictional_words.values())\n",
    "random.seed(42)\n",
    "for k,v in fictional_words.items():\n",
    "    word = k\n",
    "    definition = v[:-1] # to remove dot\n",
    "    statement = generate_statement(word, definition, templates)\n",
    "    object_1 = word\n",
    "    object_2 = definition\n",
    "    correct_object_2 = definition\n",
    "    rows.append([statement, object_1, object_2, correct_object_2, 0, 0, 0, 0, 1, \"definition\", 0])\n",
    "    ## Add NEGATION\n",
    "    word = k\n",
    "    definition = v\n",
    "    statement =generate_statement(word, definition, negated_templates)\n",
    "    object_1 = word\n",
    "    object_2 = definition\n",
    "    correct_object_2 = definition\n",
    "    rows.append([statement, object_1, object_2, correct_object_2, 0, 1, 0, 0, 1, \"definition\", 0])\n",
    "results = pl.DataFrame(rows, schema=columns)\n",
    "results.write_csv(parent_dir + \"/definitions_fake.csv\")\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belief_representation-TQ_PkdhR-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
